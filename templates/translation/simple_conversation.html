{% extends 'base.html' %}
{% load static %}

{% block title %}Simple Conversation - Globespeak{% endblock %}

{% block content %}
<div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
    <!-- Header -->
    <div class="mb-8 text-center">
        <h1 class="text-3xl font-bold text-gray-900 mb-2">Simple Conversation üéß</h1>
        <p class="text-gray-600">Speak in your language, hear in theirs..</p>
        
        <!-- Security Warning for Mobile -->
        <div id="security-warning" class="mt-4 p-4 bg-yellow-100 border border-yellow-400 rounded-lg hidden">
            <p class="text-yellow-800 text-sm">
                <strong>‚ö†Ô∏è Mobile Users:</strong> For microphone access to work, please use HTTPS or localhost. 
                If you're seeing "processing" without output, check browser console for microphone access errors.
            </p>
        </div>
    </div>

    <!-- Language Selection -->
    <div class="bg-white rounded-xl shadow-lg border border-gray-100 p-6 mb-8">
        <h3 class="text-lg font-semibold text-gray-900 mb-4 text-center">Select Languages</h3>
        <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
            <div>
                <label class="block text-sm font-medium text-gray-700 mb-2">Your Language</label>
                <select id="my-language" class="w-full border-gray-300 rounded-lg focus:ring-primary-500 focus:border-primary-500">
                    {% for code, name in supported_languages.items %}
                    <option value="{{ code }}" {% if code == 'hi' %}selected{% endif %}>{{ name }} ({{ code }})</option>
                    {% endfor %}
                </select>
            </div>
            <div>
                <label class="block text-sm font-medium text-gray-700 mb-2">Their Language</label>
                <select id="their-language" class="w-full border-gray-300 rounded-lg focus:ring-primary-500 focus:border-primary-500">
                    {% for code, name in supported_languages.items %}
                    <option value="{{ code }}" {% if code == 'en' %}selected{% endif %}>{{ name }} ({{ code }})</option>
                    {% endfor %}
                </select>
            </div>
        </div>
        
        <!-- Conversation Controls -->
        <div class="mt-6 text-center">
            <button id="start-conversation" class="bg-green-600 hover:bg-green-700 text-white px-8 py-3 rounded-lg font-semibold transition-colors">
                üéØ Start Conversation
            </button>
            <button id="end-conversation" class="bg-red-600 hover:bg-red-700 text-white px-8 py-3 rounded-lg font-semibold transition-colors ml-4 hidden">
                ‚èπÔ∏è End Conversation
            </button>
        </div>
        
        <!-- Status Display -->
        <div id="status-display" class="mt-4 text-center hidden">
            <div class="inline-flex items-center bg-blue-100 text-blue-800 px-4 py-2 rounded-lg">
                <span id="conversation-status" class="text-lg font-semibold">üéØ Ready to start</span>
            </div>
        </div>
    </div>

    <!-- Conversation Interface -->
    <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
        <!-- Your Side -->
        <div id="my-side" class="bg-white rounded-xl shadow-lg border border-gray-100">
            <div class="p-6 border-b border-gray-100">
                <h3 class="text-lg font-semibold text-gray-900 text-center">You Speak</h3>
                <p id="my-lang-display" class="text-sm text-gray-600 text-center">Hindi</p>
            </div>
            <div class="p-6">
                <div class="text-center">
                    <button id="my-mic-btn" class="w-24 h-24 bg-gray-400 text-white rounded-full flex items-center justify-center mx-auto mb-4 transition-colors cursor-not-allowed" disabled>
                        <span class="text-3xl">üé§</span>
                    </button>
                    <p class="text-sm text-gray-600 mb-4">Hold to speak (max 10s)</p>
                    <div id="my-status" class="text-sm text-gray-500">Waiting for conversation to start</div>
                </div>
            </div>
        </div>

        <!-- Their Side -->
        <div id="their-side" class="bg-white rounded-xl shadow-lg border border-gray-100">
            <div class="p-6 border-b border-gray-100">
                <h3 class="text-lg font-semibold text-gray-900 text-center">They Speak</h3>
                <p id="their-lang-display" class="text-sm text-gray-600 text-center">English</p>
            </div>
            <div class="p-6">
                <div class="text-center">
                    <button id="their-mic-btn" class="w-24 h-24 bg-gray-400 text-white rounded-full flex items-center justify-center mx-auto mb-4 transition-colors cursor-not-allowed" disabled>
                        <span class="text-3xl">üé§</span>
                    </button>
                    <p class="text-sm text-gray-600 mb-4">Hold to speak (max 10s)</p>
                    <div id="their-status" class="text-sm text-gray-500">Waiting for conversation to start</div>
                </div>
            </div>
        </div>
    </div>

    <!-- Conversation History -->
    <div class="mt-8 bg-white rounded-xl shadow-lg border border-gray-100">
        <div class="p-6 border-b border-gray-100">
            <h3 class="text-lg font-semibold text-gray-900">Conversation</h3>
        </div>
        <div class="p-6">
            <div id="conversation-history" class="space-y-4 max-h-96 overflow-y-auto">
                <div class="text-center text-gray-500 py-8">
                    <div class="text-2xl mb-2">üí¨</div>
                    <p>Start speaking to begin the conversation</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Instructions -->
    <div class="mt-8 bg-blue-50 border border-blue-200 rounded-xl p-6">
        <h3 class="text-lg font-semibold text-blue-900 mb-3">How to Use:</h3>
        <div class="space-y-2 text-sm text-blue-800">
            <p>1. <strong>Select languages</strong> - Choose what you'll speak and what they'll speak</p>
            <p>2. <strong>Hold the microphone button</strong> - Press and hold to speak</p>
            <p>3. <strong>Speak clearly</strong> - The system will translate and play to the other person</p>
            <p>4. <strong>Take turns</strong> - Both people can speak whenever they want</p>
        </div>
    </div>
</div>

<!-- Audio Elements -->
<audio id="audio-player" preload="none"></audio>

<script>
document.addEventListener('DOMContentLoaded', function() {
    // Check for mobile and show security warning
    const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    const isHTTPS = location.protocol === 'https:';
    const isLocalhost = location.hostname === 'localhost' || location.hostname === '127.0.0.1';
    
    if (isMobile && !isHTTPS && !isLocalhost) {
        document.getElementById('security-warning').classList.remove('hidden');
    }
    
    // Variables
    let myLanguage = 'hi';
    let theirLanguage = 'en';
    let isRecording = false;
    let mediaRecorder = null;
    let audioChunks = [];
    let currentSpeaker = null;
    let conversationActive = false;
    let recordingTimer = null;
    let isMyTurn = true; // Start with user's turn
    let isProcessing = false; // Prevent multiple recordings during processing

    // DOM elements
    const myLanguageSelect = document.getElementById('my-language');
    const theirLanguageSelect = document.getElementById('their-language');
    const myLangDisplay = document.getElementById('my-lang-display');
    const theirLangDisplay = document.getElementById('their-lang-display');
    const myMicBtn = document.getElementById('my-mic-btn');
    const theirMicBtn = document.getElementById('their-mic-btn');
    const myStatus = document.getElementById('my-status');
    const theirStatus = document.getElementById('their-status');
    const conversationHistory = document.getElementById('conversation-history');
    const audioPlayer = document.getElementById('audio-player');
    const startBtn = document.getElementById('start-conversation');
    const endBtn = document.getElementById('end-conversation');
    const statusDisplay = document.getElementById('status-display');
    const conversationStatus = document.getElementById('conversation-status');
    const mySide = document.getElementById('my-side');
    const theirSide = document.getElementById('their-side');

    // Initialize
    setupEventListeners();
    updateLanguageDisplays();

    function setupEventListeners() {
        myLanguageSelect.addEventListener('change', function() {
            myLanguage = this.value;
            updateLanguageDisplays();
        });

        theirLanguageSelect.addEventListener('change', function() {
            theirLanguage = this.value;
            updateLanguageDisplays();
        });

        // Start/End conversation buttons
        startBtn.addEventListener('click', startConversation);
        endBtn.addEventListener('click', endConversation);

        // Mouse events for microphone buttons
        myMicBtn.addEventListener('mousedown', () => startRecording('me'));
        myMicBtn.addEventListener('mouseup', stopRecording);
        myMicBtn.addEventListener('mouseleave', stopRecording);

        theirMicBtn.addEventListener('mousedown', () => startRecording('them'));
        theirMicBtn.addEventListener('mouseup', stopRecording);
        theirMicBtn.addEventListener('mouseleave', stopRecording);

        // Touch events for mobile
        myMicBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            startRecording('me');
        });
        myMicBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            stopRecording();
        });

        theirMicBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            startRecording('them');
        });
        theirMicBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            stopRecording();
        });
    }

    function updateLanguageDisplays() {
        const myLangName = myLanguageSelect.options[myLanguageSelect.selectedIndex].text.split(' (')[0];
        const theirLangName = theirLanguageSelect.options[theirLanguageSelect.selectedIndex].text.split(' (')[0];
        
        myLangDisplay.textContent = myLangName;
        theirLangDisplay.textContent = theirLangName;
    }

    function startConversation() {
        conversationActive = true;
        isMyTurn = true;
        isProcessing = false;
        
        // Update UI
        startBtn.classList.add('hidden');
        endBtn.classList.remove('hidden');
        statusDisplay.classList.remove('hidden');
        
        // Disable language selection
        myLanguageSelect.disabled = true;
        theirLanguageSelect.disabled = true;
        
        // Enable both microphones - users can speak when ready
        enableBothMicrophones();
        updateStatus('üéØ Conversation started! You can speak first');
    }

    function endConversation() {
        conversationActive = false;
        isProcessing = false;
        
        // Clear any timers
        if (recordingTimer) {
            clearTimeout(recordingTimer);
            recordingTimer = null;
        }
        
        // Stop any ongoing recording
        if (isRecording) {
            stopRecording();
        }
        
        // Update UI
        startBtn.classList.remove('hidden');
        endBtn.classList.add('hidden');
        statusDisplay.classList.add('hidden');
        
        // Enable language selection
        myLanguageSelect.disabled = false;
        theirLanguageSelect.disabled = false;
        
        // Reset microphone buttons
        resetMicrophoneButtons();
        
        // Clear status
        myStatus.textContent = 'Waiting for conversation to start';
        theirStatus.textContent = 'Waiting for conversation to start';
    }

    function enableBothMicrophones() {
        myMicBtn.disabled = false;
        myMicBtn.className = 'w-24 h-24 bg-red-500 hover:bg-red-600 text-white rounded-full flex items-center justify-center mx-auto mb-4 transition-colors cursor-pointer';
        myStatus.textContent = 'Hold to speak (max 10s)';
        
        theirMicBtn.disabled = false;
        theirMicBtn.className = 'w-24 h-24 bg-blue-500 hover:bg-blue-600 text-white rounded-full flex items-center justify-center mx-auto mb-4 transition-colors cursor-pointer';
        theirStatus.textContent = 'Hold to speak (max 10s)';
    }

    function resetMicrophoneButtons() {
        myMicBtn.disabled = true;
        myMicBtn.className = 'w-24 h-24 bg-gray-400 text-white rounded-full flex items-center justify-center mx-auto mb-4 transition-colors cursor-not-allowed';
        theirMicBtn.disabled = true;
        theirMicBtn.className = 'w-24 h-24 bg-gray-400 text-white rounded-full flex items-center justify-center mx-auto mb-4 transition-colors cursor-not-allowed';
    }

    function updateStatus(message) {
        conversationStatus.textContent = message;
    }

    function startRecording(speaker) {
        if (isRecording || !conversationActive || isProcessing) return;
        
        currentSpeaker = speaker;
        isRecording = true;
        
        // Update UI
        if (speaker === 'me') {
            myMicBtn.classList.add('bg-red-600');
            myStatus.textContent = 'Recording...';
            updateStatus('üé§ You are speaking...');
        } else {
            theirMicBtn.classList.add('bg-blue-600');
            theirStatus.textContent = 'Recording...';
            updateStatus('üé§ They are speaking...');
        }

        // Get microphone access with proper error handling
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            updateStatus('‚ùå Microphone access not supported. Please use HTTPS or localhost.');
            if (isMyTurn) {
                myMicBtn.classList.remove('bg-red-600');
                myStatus.textContent = 'Click to speak';
            } else {
                theirMicBtn.classList.remove('bg-blue-600');
                theirStatus.textContent = 'Click to speak';
            }
            return;
        }

        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                // Try to use WAV format first, fallback to WebM
                let mimeType = 'audio/wav';
                if (!MediaRecorder.isTypeSupported('audio/wav')) {
                    mimeType = 'audio/webm;codecs=opus';
                }
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: mimeType
                });
                audioChunks = [];
                
                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: mimeType });
                    processAudio(audioBlob, speaker);
                };
                
                mediaRecorder.start();
                
                // Auto-stop recording after 10 seconds
                recordingTimer = setTimeout(() => {
                    if (isRecording) {
                        stopRecording();
                    }
                }, 10000);
            })
            .catch(e => {
                console.error('Microphone access denied:', e);
                let errorMessage = 'Microphone access is required for this feature.';
                
                if (e.name === 'NotAllowedError') {
                    errorMessage = 'Microphone access denied. Please allow microphone access and try again.';
                } else if (e.name === 'NotFoundError') {
                    errorMessage = 'No microphone found. Please connect a microphone and try again.';
                } else if (e.name === 'NotSupportedError') {
                    errorMessage = 'Microphone access not supported. Please use HTTPS or localhost.';
                } else if (e.name === 'SecurityError') {
                    errorMessage = 'Security error. Please use HTTPS or localhost for microphone access.';
                }
                
                updateStatus('‚ùå ' + errorMessage);
                alert(errorMessage);
                stopRecording();
            });
    }

    function stopRecording() {
        if (!isRecording) return;
        
        isRecording = false;
        
        // Clear the 10-second timer
        if (recordingTimer) {
            clearTimeout(recordingTimer);
            recordingTimer = null;
        }
        
        // Update UI
        if (currentSpeaker === 'me') {
            myMicBtn.classList.remove('bg-red-600');
            myStatus.textContent = 'Processing...';
        } else {
            theirMicBtn.classList.remove('bg-blue-600');
            theirStatus.textContent = 'Processing...';
        }
        
        updateStatus('üîÑ Processing speech...');

        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
        }
    }

    async function processAudio(audioBlob, speaker) {
        try {
            // Convert audio to base64
            const base64Audio = await blobToBase64(audioBlob);
            
            // Determine source and target languages
            const sourceLang = speaker === 'me' ? myLanguage : theirLanguage;
            const targetLang = speaker === 'me' ? theirLanguage : myLanguage;
            
            // Send to server for processing
            const response = await fetch('/api/process-conversation-audio/', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'X-CSRFToken': getCookie('csrftoken')
                },
                body: JSON.stringify({
                    audio_data: base64Audio,
                    source_language: sourceLang,
                    target_language: targetLang,
                    speaker: speaker
                })
            });

            const result = await response.json();
            
            if (result.success) {
                // Add to conversation history
                addToHistory(speaker, result.transcribed_text, result.translated_text, result.audio_url);
                
                // Play translated audio
                if (result.audio_url) {
                    playAudio(result.audio_url);
                }
                
                // Switch turns after successful processing
                if (conversationActive) {
                    switchTurns();
                }
            } else {
                console.error('Processing failed:', result.error);
                addToHistory('system', `Error: ${result.error}`);
                updateStatus('‚ùå Processing failed. Try speaking again.');
            }
        } catch (error) {
            console.error('Error processing audio:', error);
            addToHistory('system', 'Error processing audio');
        } finally {
            isProcessing = false;
            // Reset UI will be handled by switchTurns or error handling
        }
    }

    function switchTurns() {
        isMyTurn = !isMyTurn;
        
        if (isMyTurn) {
            updateStatus('üéØ Your turn to speak');
            myStatus.textContent = 'Hold to speak (max 10s)';
            theirStatus.textContent = 'Waiting for your turn';
        } else {
            updateStatus('üéØ Their turn to speak');
            theirStatus.textContent = 'Hold to speak (max 10s)';
            myStatus.textContent = 'Waiting for their turn';
        }
    }

    function addToHistory(speaker, originalText, translatedText, audioUrl) {
        const historyDiv = document.createElement('div');
        historyDiv.className = 'bg-gray-50 rounded-lg p-4';
        
        let content = `
            <div class="flex items-start justify-between">
                <div class="flex-1">
                    <div class="flex items-center space-x-2 mb-2">
                        <span class="font-medium text-gray-900">${speaker === 'me' ? 'You' : 'Them'}</span>
                        <span class="text-xs text-gray-500">${new Date().toLocaleTimeString()}</span>
                    </div>
        `;
        
        if (originalText) {
            content += `<p class="text-gray-700 mb-2">${originalText}</p>`;
        }
        
        if (translatedText && translatedText !== originalText) {
            content += `<p class="text-blue-700 italic">${translatedText}</p>`;
        }
        
        if (audioUrl) {
            content += `
                <div class="mt-2">
                    <audio controls class="w-full">
                        <source src="${audioUrl}" type="audio/mpeg">
                    </audio>
                </div>
            `;
        }
        
        content += `
                </div>
            </div>
        `;
        
        historyDiv.innerHTML = content;
        
        // Remove "no conversation yet" message if it exists
        const noConversation = conversationHistory.querySelector('.text-center');
        if (noConversation) {
            noConversation.remove();
        }
        
        conversationHistory.appendChild(historyDiv);
        conversationHistory.scrollTop = conversationHistory.scrollHeight;
    }

    function playAudio(url) {
        audioPlayer.src = url;
        audioPlayer.play().catch(e => console.error('Audio play failed:', e));
    }

    function blobToBase64(blob) {
        return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = () => {
                const arrayBuffer = reader.result;
                
                // Convert to WAV using Web Audio API
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                audioContext.decodeAudioData(arrayBuffer)
                    .then(audioBuffer => {
                        // Convert to WAV format
                        const wavBlob = audioBufferToWav(audioBuffer);
                        const wavReader = new FileReader();
                        wavReader.onload = () => resolve(wavReader.result);
                        wavReader.onerror = reject;
                        wavReader.readAsDataURL(wavBlob);
                    })
                    .catch(error => {
                        console.error('Audio decode error:', error);
                        // Fallback to original blob
                        const fallbackReader = new FileReader();
                        fallbackReader.onload = () => resolve(fallbackReader.result);
                        fallbackReader.onerror = reject;
                        fallbackReader.readAsDataURL(blob);
                    });
            };
            reader.onerror = reject;
            reader.readAsArrayBuffer(blob);
        });
    }
    
    function audioBufferToWav(buffer) {
        const length = buffer.length;
        const sampleRate = buffer.sampleRate;
        const arrayBuffer = new ArrayBuffer(44 + length * 2);
        const view = new DataView(arrayBuffer);
        
        // WAV header
        const writeString = (offset, string) => {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        };
        
        writeString(0, 'RIFF');
        view.setUint32(4, 36 + length * 2, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, 1, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, 16, true);
        writeString(36, 'data');
        view.setUint32(40, length * 2, true);
        
        // Convert float samples to 16-bit PCM
        const channelData = buffer.getChannelData(0);
        let offset = 44;
        for (let i = 0; i < length; i++) {
            const sample = Math.max(-1, Math.min(1, channelData[i]));
            view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
            offset += 2;
        }
        
        return new Blob([arrayBuffer], { type: 'audio/wav' });
    }

    function getCookie(name) {
        let cookieValue = null;
        if (document.cookie && document.cookie !== '') {
            const cookies = document.cookie.split(';');
            for (let i = 0; i < cookies.length; i++) {
                const cookie = cookies[i].trim();
                if (cookie.substring(0, name.length + 1) === (name + '=')) {
                    cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                    break;
                }
            }
        }
        return cookieValue;
    }
});
</script>
{% endblock %}

        // Update UI

        if (speaker === 'me') {

            myMicBtn.classList.add('bg-red-600');

            myStatus.textContent = 'Recording...';

            updateStatus('üé§ You are speaking...');

        } else {

            theirMicBtn.classList.add('bg-blue-600');

            theirStatus.textContent = 'Recording...';

            updateStatus('üé§ They are speaking...');

        }



        // Get microphone access

        navigator.mediaDevices.getUserMedia({ audio: true })

            .then(stream => {

                // Try to use WAV format first, fallback to WebM

                let mimeType = 'audio/wav';

                if (!MediaRecorder.isTypeSupported('audio/wav')) {

                    mimeType = 'audio/webm;codecs=opus';

                }

                

                mediaRecorder = new MediaRecorder(stream, {

                    mimeType: mimeType

                });

                audioChunks = [];

                

                mediaRecorder.ondataavailable = event => {

                    audioChunks.push(event.data);

                };

                

                mediaRecorder.onstop = () => {

                    const audioBlob = new Blob(audioChunks, { type: mimeType });

                    processAudio(audioBlob, speaker);

                };

                

                mediaRecorder.start();

                

                // Auto-stop recording after 10 seconds

                recordingTimer = setTimeout(() => {

                    if (isRecording) {

                        stopRecording();

                    }

                }, 10000);

            })

            .catch(e => {

                console.error('Microphone access denied:', e);

                alert('Microphone access is required for this feature');

                stopRecording();

            });

    }



    function stopRecording() {

        if (!isRecording) return;

        

        isRecording = false;

        

        // Clear the 10-second timer

        if (recordingTimer) {

            clearTimeout(recordingTimer);

            recordingTimer = null;

        }

        

        // Update UI

        if (currentSpeaker === 'me') {

            myMicBtn.classList.remove('bg-red-600');

            myStatus.textContent = 'Processing...';

        } else {

            theirMicBtn.classList.remove('bg-blue-600');

            theirStatus.textContent = 'Processing...';

        }

        

        updateStatus('üîÑ Processing speech...');



        if (mediaRecorder && mediaRecorder.state === 'recording') {

            mediaRecorder.stop();

        }

    }



    async function processAudio(audioBlob, speaker) {

        try {

            // Convert audio to base64

            const base64Audio = await blobToBase64(audioBlob);

            

            // Determine source and target languages

            const sourceLang = speaker === 'me' ? myLanguage : theirLanguage;

            const targetLang = speaker === 'me' ? theirLanguage : myLanguage;

            

            // Send to server for processing

            const response = await fetch('/api/process-conversation-audio/', {

                method: 'POST',

                headers: {

                    'Content-Type': 'application/json',

                    'X-CSRFToken': getCookie('csrftoken')

                },

                body: JSON.stringify({

                    audio_data: base64Audio,

                    source_language: sourceLang,

                    target_language: targetLang,

                    speaker: speaker

                })

            });



            const result = await response.json();

            

            if (result.success) {

                // Add to conversation history

                addToHistory(speaker, result.transcribed_text, result.translated_text, result.audio_url);

                

                // Play translated audio

                if (result.audio_url) {

                    playAudio(result.audio_url);

                }

                

                // Switch turns after successful processing

                if (conversationActive) {

                    switchTurns();

                }

            } else {

                console.error('Processing failed:', result.error);

                addToHistory('system', `Error: ${result.error}`);

                updateStatus('‚ùå Processing failed. Try speaking again.');

            }

        } catch (error) {

            console.error('Error processing audio:', error);

            addToHistory('system', 'Error processing audio');

        } finally {

            isProcessing = false;

            // Reset UI will be handled by switchTurns or error handling

        }

    }



    function switchTurns() {

        isMyTurn = !isMyTurn;

        

        if (isMyTurn) {

            updateStatus('üéØ Your turn to speak');

            myStatus.textContent = 'Hold to speak (max 10s)';

            theirStatus.textContent = 'Waiting for your turn';

        } else {

            updateStatus('üéØ Their turn to speak');

            theirStatus.textContent = 'Hold to speak (max 10s)';

            myStatus.textContent = 'Waiting for their turn';

        }

    }



    function addToHistory(speaker, originalText, translatedText, audioUrl) {

        const historyDiv = document.createElement('div');

        historyDiv.className = 'bg-gray-50 rounded-lg p-4';

        

        let content = `

            <div class="flex items-start justify-between">

                <div class="flex-1">

                    <div class="flex items-center space-x-2 mb-2">

                        <span class="font-medium text-gray-900">${speaker === 'me' ? 'You' : 'Them'}</span>

                        <span class="text-xs text-gray-500">${new Date().toLocaleTimeString()}</span>

                    </div>

        `;

        

        if (originalText) {

            content += `<p class="text-gray-700 mb-2">${originalText}</p>`;

        }

        

        if (translatedText && translatedText !== originalText) {

            content += `<p class="text-blue-700 italic">${translatedText}</p>`;

        }

        

        if (audioUrl) {

            content += `

                <div class="mt-2">

                    <audio controls class="w-full">

                        <source src="${audioUrl}" type="audio/mpeg">

                    </audio>

                </div>

            `;

        }

        

        content += `

                </div>

            </div>

        `;

        

        historyDiv.innerHTML = content;

        

        // Remove "no conversation yet" message if it exists

        const noConversation = conversationHistory.querySelector('.text-center');

        if (noConversation) {

            noConversation.remove();

        }

        

        conversationHistory.appendChild(historyDiv);

        conversationHistory.scrollTop = conversationHistory.scrollHeight;

    }



    function playAudio(url) {

        audioPlayer.src = url;

        audioPlayer.play().catch(e => console.error('Audio play failed:', e));

    }



    function blobToBase64(blob) {

        return new Promise((resolve, reject) => {

            const reader = new FileReader();

            reader.onload = () => {

                const arrayBuffer = reader.result;

                

                // Convert to WAV using Web Audio API

                const audioContext = new (window.AudioContext || window.webkitAudioContext)();

                audioContext.decodeAudioData(arrayBuffer)

                    .then(audioBuffer => {

                        // Convert to WAV format

                        const wavBlob = audioBufferToWav(audioBuffer);

                        const wavReader = new FileReader();

                        wavReader.onload = () => resolve(wavReader.result);

                        wavReader.onerror = reject;

                        wavReader.readAsDataURL(wavBlob);

                    })

                    .catch(error => {

                        console.error('Audio decode error:', error);

                        // Fallback to original blob

                        const fallbackReader = new FileReader();

                        fallbackReader.onload = () => resolve(fallbackReader.result);

                        fallbackReader.onerror = reject;

                        fallbackReader.readAsDataURL(blob);

                    });

            };

            reader.onerror = reject;

            reader.readAsArrayBuffer(blob);

        });

    }

    

    function audioBufferToWav(buffer) {

        const length = buffer.length;

        const sampleRate = buffer.sampleRate;

        const arrayBuffer = new ArrayBuffer(44 + length * 2);

        const view = new DataView(arrayBuffer);

        

        // WAV header

        const writeString = (offset, string) => {

            for (let i = 0; i < string.length; i++) {

                view.setUint8(offset + i, string.charCodeAt(i));

            }

        };

        

        writeString(0, 'RIFF');

        view.setUint32(4, 36 + length * 2, true);

        writeString(8, 'WAVE');

        writeString(12, 'fmt ');

        view.setUint32(16, 16, true);

        view.setUint16(20, 1, true);

        view.setUint16(22, 1, true);

        view.setUint32(24, sampleRate, true);

        view.setUint32(28, sampleRate * 2, true);

        view.setUint16(32, 2, true);

        view.setUint16(34, 16, true);

        writeString(36, 'data');

        view.setUint32(40, length * 2, true);

        

        // Convert float samples to 16-bit PCM

        const channelData = buffer.getChannelData(0);

        let offset = 44;

        for (let i = 0; i < length; i++) {

            const sample = Math.max(-1, Math.min(1, channelData[i]));

            view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);

            offset += 2;

        }

        

        return new Blob([arrayBuffer], { type: 'audio/wav' });

    }



    function getCookie(name) {

        let cookieValue = null;

        if (document.cookie && document.cookie !== '') {

            const cookies = document.cookie.split(';');

            for (let i = 0; i < cookies.length; i++) {

                const cookie = cookies[i].trim();

                if (cookie.substring(0, name.length + 1) === (name + '=')) {

                    cookieValue = decodeURIComponent(cookie.substring(name.length + 1));

                    break;

                }

            }

        }

        return cookieValue;

    }

;

</script>



